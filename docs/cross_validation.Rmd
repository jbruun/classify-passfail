---
title: "Cross-validation notes"
author: "Jesper Bruun & Adrienne Traxler"
date: "25 Jan 2021--"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Goal for this document is to summarize results from the cross-validation methods we used: Leave One Out Cross-Validation aka LOOCV aka jackknife, and k-fold cross-validation with `k=5` and `k=10`.

**Update 25 Mar:** Updated success rates (LOOCV files were using an outdated set of predictors) and remade the facet grid plot. 

```{r packages, echo = FALSE, message = FALSE}
library(igraph)
library(tidyr)
library(dplyr)
library(ggplot2)
library(tibble)
library(forcats)
```

## Import data

At this point, the following R scripts have already been run. 

* For LOOCV: `passfail_logreg_jackknife`, `passfail_lda_jackknife`, `passfail_qda_jackknife`, and `passfail_knn_jackknife`. 
* For k-fold cross-validation: `passfail_logreg_kfold`, `passfail_lda_lfold`, `passfail_qda_kfold` (ultimately not used, see notes below), and `passfail_knn_kfold`. 

Each of those files saves the predictions in an .Rdata file in the `data` directory and the success rate table in the `results` directory. Results are saved separately for the full set of pass/fail outcomes and for students who were just on the pass/fail border (the justpass outcome, saved in `Just` files). The k-fold results were saved for `k=5` and `k=10`. 

```{r}
filelist <- list.files(path = "../results", pattern = "*.csv")
infiles <- file.path("../results", filelist)
infiles 
allSuccRates <- lapply(infiles, read.csv) 
summary(allSuccRates)
```


### Clean up and organize

I want to name these appropriately and reorder them. Make sure each name is tagged with `pass` or `justpass` so I can use that below. 

```{r}
succLabels <- gsub("succRate", "", filelist) %>% 
  gsub(".csv", "", .) %>% 
  gsub("^_", "", .) %>% 
  paste0("pass.", .) %>% 
  gsub("^pass.Just_", "justpass.", .)
names(allSuccRates) <- succLabels
names(allSuccRates)

# Reorder to (logReg, LDA, QDA, KNN, (repeats for justpass))
newOrder <- c(8, 10, 9, 5, 7, 6, 11, 1, 3, 2)  
allSuccRates <- allSuccRates[c(newOrder, newOrder + 11)]
```

Now I'd like to put these into a long data frame so I can plot them more easily. In the process, I separate the `pass`/`justpass` label into its own column. 

```{r}
# see https://gist.github.com/aammd/9ae2f5cce9afd799bafb
succRateWide <- enframe(allSuccRates) %>% 
  unnest(cols = value) %>% 
  separate(col = name, into = c("outcome", "name"), sep = "[.]")
succRateWide
```

Finally, turn that wide frame (separate column for each week) into a long one (column for week number + single column for result). While I'm at it, factor-ize the name of the method used and reorder the levels. 

```{r}
succRateLong <- succRateWide %>% 
  pivot_longer(cols = starts_with("Week"), names_to = "Week", names_prefix = "Week", 
               names_transform = list(Week = as.integer), values_to = "succRate") %>% 
  relocate(Week, .before = N)
# Factor-ize and reorder
succRateLong$outcome <- factor(succRateLong$outcome, levels = c("pass", "justpass"))
succRateLong$method <- factor(succRateLong$name)  
succRateLong$method <- fct_relevel(succRateLong$method, 
                                   levels(succRateLong$method)[c(7, 9, 8, 4, 6, 5, 10, 1, 3, 2)])
succRateLong
```



### Plot success rates

Not sure I can put everything on one readable plot. What I'm trying to combine is my various success rate figures. Do a facet grid with `name` as the horizontal variable and `outcome` as the vertical?

```{r, succ-rate-plot, fig.dim = c(9.5, 6)}
succRateLong %>% ggplot(mapping = aes(x = Week, y = succRate, color = Layer)) +
  geom_line() + 
  facet_grid(rows = vars(outcome), cols = vars(method)) + 
  geom_hline(aes(yintercept = Guessing))
  
```

There's no CD layer line for qda because I got an error when running that, and the errors intensified for k-fold cross validation. So that looks like an unfruitful line to pursue. 


**Thoughts:**

Now that I finally have them all collected side-by-side, what's the picture? 

* Results by outcome: `pass` is generally more stable from week-to-week than `justpass`. That could be a sample size thing (probably) or possibly less consistent attendance. 

* Methods: QDA and KNN are more variable and perform worse for `pass` than logistic regression or LDA do. That's less true for `justpass`, though KNN still bounces around a lot. 

* Network layer: For the `pass` outcome and logreg or LDA, the three lines track each other pretty well. For `justpass`, ICS emerges as the usually-best case. An exception is the cross-validation runs of K nearest neighbors, where CD is drastically better in week 1 and then drops down. 

* Leave One Out vs. K-fold cross validation: Comparing success rates on the two types of cross validation for the `pass` outcome. They look very similar for logistic regression and LDA, and k-fold is slightly worse for KNN. For the `justpass` outcome, k-fold with `k = 5` looks a bit better for logistic regression and LDA, and basically the same for KNN (barring that week 1 CD spike). 