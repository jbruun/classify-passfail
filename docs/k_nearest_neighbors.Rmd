---
title: "K nearest neighbors"
author: "Jesper Bruun & Adrienne Traxler"
date: "8/18/2020--"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Goal for this document is to use K nearest neighbors to predict passing and just-passing in the (single-layer) PS, CD, and ICS weekly networks. Calculate success rates for each week and save.

**Update 8/18:** Starting this file to document calculations I worked out in `passfail_KNN_jackknife.R`. 

```{r packages, echo = FALSE, message = FALSE}
library(igraph)
library(tidyr)
library(dplyr)
library(ggplot2)
```

## Import data

At this point, the following Rmd files have already been run: `loadAllNetworks`, `calculatePR_TE_H`, and `make_node_data_frames`. Importing the results of that gives me three long data frames. Each has all the node info and centrality values, by week, for a single layer. 

```{r}
(load("../data/centrality_data_frames.Rdata"))
```


## Jackknife K nearest neighbors

Because of the data set size, we'll use a "jackknife" approach, where each observation is removed, the remaining observations are used to predict the missing one, and then we repeat until we've checked them all. 

Turn the long data frames into lists of single (weekly) data frames: 

```{r}
centPS <- dfPS %>% group_split(Week)
centCD <- dfCD %>% group_split(Week)
centICS <- dfICS %>% group_split(Week)

centPS[[1]]
```

### Jackknife loop

Next, the function that actually does the calculations. 

* Input: A list of weekly data frames, optional outcome (pass/justpass, defaults to "pass"), and an optional subset of predictors to use (defaults gender, cohort, FCI pre, and centrality)
* Output: A list with two items. The first is the number of neighbors used (`nK`); the second is a data frame with node names, pass/fail outcome, and prediction vectors for that weekly aggregate network. Each node is predicted using all the other nodes in its week.

```{r}
jackPred <- function(layer, nK = 1, outcome = "pass", 
                     predictors = c("gender", "cohort", "fci_pre", "PageRank", 
                                    "tarEnt", "Hide")) {
  if (outcome == "pass" | outcome == "justpass") {
    choices <- c("0", "1")
  } else {
    stop("Not a valid outcome variable.")
  }
  
  # Input data (complete cases) and empty frame to store predictions 
  Nlayer <- length(layer)
  userows <- complete.cases(layer[[Nlayer]][, c(outcome, predictors)])  
  allpred <- matrix(nrow = sum(userows), ncol = Nlayer)
  
  # Build fitting input string using predictor names
  fitStr <- paste(predictors, collapse = " + ")
  fitForm <- paste0(outcome, " ~ ", fitStr)

  # Loop through all weeks
  for(j in seq(Nlayer)) {
    data <- layer[[j]][userows, c(outcome, predictors)] # data is complete cases
    
    # Loop through all nodes
    for(i in 1:dim(data)[1]) {
      # training set is data minus observation i
      # Predictor matrices for training and test data
      train <- as.matrix(data[-i, predictors])
      test <- as.matrix(data[i, predictors])
      
      # Outcome vectors for training and test data
      # Can't just do data[-i, outcome], for explanation see
      # https://stackoverflow.com/questions/51063381/vector-from-tibble-has-length-0
      trOutcome <- pull(data[-i, ], var = outcome)
      teOutcome <- pull(data[i, ], var = outcome)
      
      # Run KNN
      set.seed(2)
      # Logistic regression makes probabilities, which you translate into prediction; 
      # KNN does it all in one step
      allpred[i, j] <- knn(train, test, trOutcome, k = nK)
    }
  }
  
  # Assemble data frame: Translate factor to labels, add node names and outcomes
  allpred[allpred == 1] <- choices[1] # 0
  allpred[allpred == 2] <- choices[2] # 1
  allpred <- data.frame(layer[[1]][userows, "name"],  # node names
                        data[, outcome],            # real outcome
                        as.data.frame(allpred))     # predicted outcome
  names(allpred) <- c("name", outcome, paste0("Week", c(1:length(layer))))
  
  # Print info string and return predictions
  print(paste0("Fit: ", fitForm, ", #neighbors = ", nK, 
               ", complete N = ", dim(allpred)[1]))
  return(list(nK = nK, allpred = allpred))
}
```

It takes a few seconds to run the loop, so I'll import the results rather than executing it here. I did this for each centrality data frame (PS, CD, and ICS), using demographics (Gender/Section), FCI pretest score, and all three centrality measures as predictors. The function predicts passing if P > 0.5. 

```{r}
# Predict pass/fail
#predPS <- jackPred(centPS, nK = 2)
#predCD <- jackPred(centCD, nK = 2)
#predICS <- jackPred(centICS, nK = 2)

# Predict just-pass/just-fail (2/0)
#predJustPS <- jackPred(centPS, nK = 2, outcome = "justpass")
#predJustCD <- jackPred(centCD, nK = 2, outcome = "justpass")
#predJustICS <- jackPred(centICS, nK = 2, outcome = "justpass")

load("../data/jackknife_knn1_predictions.Rda")
```


### Success rates for K = 1

We're interested in a couple of success rate comparisons: how predictions compared with reality for each week, and how well it would have worked to just guess that everyone passed.

I got tired of repasting code lines (which got clunkier with the list return format in KNN), so I wrote a function to compile this. 

* Input: Three prediction data frames, outcome variable (pass/justpass)
* Output: Success rate data frame with layer name, # of neighbors (`nK`), # of nodes (`N`), weekly prediction success rates, guessing success rate

```{r}
getSucc <- function(pPS, pCD, pICS, outcome = "pass") {
  
  # Calculate one row of success rate table:
  # Pull weekly columns and compare them with outcome (pass/justpass)
  succRow <- function(p) sapply(p[[2]][, 3:9], 
                                function(x) mean(x == p[[2]][[outcome]]))
  
  compareSucc <- rbind(succRow(pPS), succRow(pCD), succRow(pICS))

  # Number of nodes: pull from prediction data frame
  Nnodes <- c(dim(pPS[[2]])[1], dim(pCD[[2]])[1], dim(pICS[[2]])[1])
  
  # How successful is it to just guess that everyone passes?
  Guessing  <- c(mean(pPS[[2]][[outcome]] == "1"), 
                 mean(pCD[[2]][[outcome]] == "1"),
                 mean(pICS[[2]][[outcome]] == "1"))
    
  # Package all these calculations in a data frame
  succRate <- data.frame(Layer = c("PS","CD","ICS"), 
                         nK = c(pPS[[1]], pCD[[1]], pICS[[1]]),
                         N = Nnodes, 
                         compareSucc, 
                         Guessing)
  return(succRate)
}

succRate <- getSucc(predPS, predCD, predICS)
succRate
```

Now, the same calculation for only the people who were on the pass/fail boundary (2/0):
```{r}
succRateJust <- getSucc(predJustPS, predJustCD, predJustICS, "justpass")
succRateJust
```

## Summary of results

The success rate tables have the punchline here. If the success rate for a given week and layer is higher than the value in the last column (the "assume everyone passes" default classifier), that's good news. 

Doing a quick boolean comparison,
```{r}
succRate[, c(4:10)] > succRate[1, 11]
rowSums(succRate[, c(4:10)] > succRate[1, 11])
```

KNN with two neighbors actually does worse than guessing everyone passes, most of the time. 

For grades on the boundary, 

```{r}
succRateJust[, c(4:10)] > succRateJust[1, 11]
rowSums(succRateJust[, c(4:10)] > succRateJust[1, 11])
#(succRateJust[, c(4:10)] - succRateJust[1, 11]) * 100
```

Things are only marginally better for the justpass criterion. Even more than logistic regression, the K nearest neighbors classifier isn't improving as weekly data accumulates. 

### Plotting success rates

To more easily compare, I'd like to plot this too. 

```{r}
plotSucc <- function(succRate) {
  dflong <- succRate %>% 
    pivot_longer(Week1:Week7, names_to = "Week", values_to = "Rate")
  
  plotlab <- paste0("Success rate: KNN, ", median(succRate$nK), " neighbor(s)")

  ggplot(data = dflong, mapping = aes(x = Week, y = Rate)) + 
    geom_point(mapping = aes(color = Layer, shape = Layer)) + 
    geom_hline(aes(yintercept = Guessing)) + 
    ylim(0, 1) + 
    labs(title = plotlab)
}

plotSucc(succRate)
plotSucc(succRateJust)
```

